{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFDistilBertForSequenceClassification: ['vocab_transform.bias', 'vocab_projector.bias', 'vocab_layer_norm.bias', 'vocab_transform.weight', 'vocab_layer_norm.weight']\n",
      "- This IS expected if you are initializing TFDistilBertForSequenceClassification from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFDistilBertForSequenceClassification from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights or buffers of the TF 2.0 model TFDistilBertForSequenceClassification were not initialized from the PyTorch model and are newly initialized: ['pre_classifier.weight', 'pre_classifier.bias', 'classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/6\n",
      "53/53 [==============================] - 230s 4s/step - loss: 9.8755 - mae: 2.9067\n",
      "Epoch 2/6\n",
      "53/53 [==============================] - 230s 4s/step - loss: 1.7606 - mae: 1.1598\n",
      "Epoch 3/6\n",
      "53/53 [==============================] - 242s 5s/step - loss: 1.0659 - mae: 0.8049\n",
      "Epoch 4/6\n",
      "53/53 [==============================] - 266s 5s/step - loss: 0.9074 - mae: 0.7559\n",
      "Epoch 5/6\n",
      "53/53 [==============================] - 348s 7s/step - loss: 0.5610 - mae: 0.6298\n",
      "Epoch 6/6\n",
      "53/53 [==============================] - 278s 5s/step - loss: 0.3708 - mae: 0.5208\n",
      "Mean Squared Error: 0.7009488344192505\n",
      "Mean Absolute Error: 0.6126383543014526\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "Predicted Rating: [2.3879557]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import string\n",
    "from transformers import DistilBertTokenizer, TFDistilBertForSequenceClassification\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import nltk\n",
    "\n",
    "# Load your dataset (replace 'reviews.csv' with your dataset path)\n",
    "# The dataset should have columns: 'A Detailed Review of the Place' and 'On a Scale of 1-5 Rate the Place'\n",
    "df = pd.read_csv('reviews.csv', sep=',')\n",
    "\n",
    "def preprocess_text(text):\n",
    "    # Add your text preprocessing steps here\n",
    "    text = re.sub(r'http\\S+', '', text)\n",
    "    text = text.translate(str.maketrans('', '', string.punctuation))\n",
    "    text = text.lower()\n",
    "    return text\n",
    "\n",
    "df['A Detailed Review of the Place'] = df['A Detailed Review of the Place'].apply(preprocess_text)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X = df['A Detailed Review of the Place']\n",
    "y = df['On a Scale of 1-5 Rate the Place']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize DistilBERT tokenizer\n",
    "max_seq_length = 128\n",
    "tokenizer = DistilBertTokenizer.from_pretrained('distilbert-base-uncased', max_length=max_seq_length, truncation=True, padding='max_length')\n",
    "\n",
    "# Tokenize and encode the data\n",
    "x_train_encoded = tokenizer(list(X_train), return_tensors='tf', padding=True, truncation=True, max_length=max_seq_length)\n",
    "x_test_encoded = tokenizer(list(X_test), return_tensors='tf', padding=True, truncation=True, max_length=max_seq_length)\n",
    "\n",
    "# Initialize DistilBERT model for regression\n",
    "model = TFDistilBertForSequenceClassification.from_pretrained('distilbert-base-uncased', num_labels=1)  # Regression model, single output neuron\n",
    "\n",
    "loss = tf.keras.losses.MeanSquaredError()\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=1e-5)\n",
    "model.compile(optimizer=optimizer, loss=loss, metrics=['mae'])\n",
    "\n",
    "# Increase the number of epochs for better training\n",
    "epochs = 6  # Increase the number of epochs for better results\n",
    "\n",
    "# Model training on the training dataset\n",
    "history = model.fit(\n",
    "    x={'input_ids': x_train_encoded['input_ids'], 'attention_mask': x_train_encoded['attention_mask']},\n",
    "    y=y_train,\n",
    "    epochs=epochs,\n",
    "    batch_size=16\n",
    ")\n",
    "\n",
    "# Evaluate the model on the test dataset\n",
    "mse, mae = model.evaluate(\n",
    "    x={'input_ids': x_test_encoded['input_ids'], 'attention_mask': x_test_encoded['attention_mask']},\n",
    "    y=y_test,\n",
    "    verbose=0\n",
    ")\n",
    "\n",
    "print(f\"Mean Squared Error: {mse}\")\n",
    "print(f\"Mean Absolute Error: {mae}\")\n",
    "\n",
    "# Function to predict rating for a review\n",
    "def predict_rating(review):\n",
    "    # Tokenize and encode the review\n",
    "    review_encoded = tokenizer([preprocess_text(review)], return_tensors='tf', padding=True, truncation=True, max_length=max_seq_length)\n",
    "\n",
    "    # Predict rating\n",
    "    rating = model.predict({'input_ids': review_encoded['input_ids'], 'attention_mask': review_encoded['attention_mask']})\n",
    "\n",
    "    return rating[0][0]\n",
    "\n",
    "# Example usage of the predict_rating function\n",
    "predicted_rating = predict_rating(\"It wasn't that great of a place\")\n",
    "print(f\"Predicted Rating: {predicted_rating}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 44ms/step\n",
      "Predicted Rating: 4\n"
     ]
    }
   ],
   "source": [
    "predicted_rating = predict_rating(\"It was a really great place\")\n",
    "print(f\"Predicted Rating: {round(predicted_rating[0])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 43ms/step\n",
      "Predicted Rating: 5\n"
     ]
    }
   ],
   "source": [
    "predicted_rating = predict_rating(\"Amazing place, really loved it.\")\n",
    "print(f\"Predicted Rating: {round(predicted_rating[0])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 40ms/step\n",
      "Predicted Rating: 3\n"
     ]
    }
   ],
   "source": [
    "predicted_rating = predict_rating(\"It is not that great of a place\")\n",
    "print(f\"Predicted Rating: {round(predicted_rating[0])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.regularization.dropout.Dropout object at 0x000001E1A6BC6070>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.regularization.dropout.Dropout object at 0x000001E1A6BC6070>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.regularization.dropout.Dropout object at 0x000001E1A6C0B0D0>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.regularization.dropout.Dropout object at 0x000001E1A6C0B0D0>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.regularization.dropout.Dropout object at 0x000001E1A6C1A070>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.regularization.dropout.Dropout object at 0x000001E1A6C1A070>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.regularization.dropout.Dropout object at 0x000001E1A6C27040>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.regularization.dropout.Dropout object at 0x000001E1A6C27040>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.regularization.dropout.Dropout object at 0x000001E1A6C30F70>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.regularization.dropout.Dropout object at 0x000001E1A6C30F70>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.regularization.dropout.Dropout object at 0x000001E1A6C3FF10>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.regularization.dropout.Dropout object at 0x000001E1A6C3FF10>, because it is not built.\n",
      "WARNING:absl:Found untraced functions such as serving, _update_step_xla, embeddings_layer_call_fn, embeddings_layer_call_and_return_conditional_losses, transformer_layer_call_fn while saving (showing 5 of 166). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: distilbert_sentiment_model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: distilbert_sentiment_model\\assets\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('distilbert_tokenizer\\\\tokenizer_config.json',\n",
       " 'distilbert_tokenizer\\\\special_tokens_map.json',\n",
       " 'distilbert_tokenizer\\\\vocab.txt',\n",
       " 'distilbert_tokenizer\\\\added_tokens.json')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Save the model architecture and weights\n",
    "model.save('distilbert_sentiment_model', save_format='tf')\n",
    "\n",
    "# Optionally, save the tokenizer as well for future use\n",
    "tokenizer.save_pretrained('distilbert_tokenizer')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
