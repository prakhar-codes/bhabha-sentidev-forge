{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All TF 2.0 model weights were used when initializing DistilBertForSequenceClassification.\n",
      "\n",
      "All the weights of DistilBertForSequenceClassification were initialized from the TF 2.0 model.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use DistilBertForSequenceClassification for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "from transformers import DistilBertForSequenceClassification, DistilBertTokenizer\n",
    "import joblib\n",
    "\n",
    "# Load the saved model and tokenizer from TensorFlow weights\n",
    "model_path = 'distilbert_model_new'\n",
    "model = DistilBertForSequenceClassification.from_pretrained(model_path, from_tf=True)\n",
    "tokenizer = DistilBertTokenizer.from_pretrained(model_path)\n",
    "\n",
    "# Load the label encoder\n",
    "label_encoder = joblib.load('label_encoder.joblib')\n",
    "\n",
    "# Now, you can use the loaded model, tokenizer, and label encoder\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import string\n",
    "import numpy as np\n",
    "import torch\n",
    "max_seq_length = 128\n",
    "def preprocess_text(text):\n",
    "    # Add your text preprocessing steps here\n",
    "    text = re.sub(r'http\\S+', '', text)\n",
    "    text = text.translate(str.maketrans('', '', string.punctuation))\n",
    "    text = text.lower()\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to predict sentiment\n",
    "def predict_sentiment(review):\n",
    "    # Tokenize the input text\n",
    "    inputs = tokenizer(review, padding=True, truncation=True, return_tensors=\"pt\")\n",
    "    \n",
    "    # Perform inference\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "        logits = outputs.logits\n",
    "\n",
    "    # Determine the predicted sentiment label\n",
    "    predicted_label = torch.argmax(logits, dim=1).item()\n",
    "    \n",
    "    # Map the predicted label to your desired labels (1, 2, 3, 4, 5)\n",
    "    sentiment_label = predicted_label + 1\n",
    "    \n",
    "    return sentiment_label\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Sentiment: 5\n"
     ]
    }
   ],
   "source": [
    "review = \"Worst place\"\n",
    "predicted_sentiment = predict_sentiment(review)\n",
    "print(\"Predicted Sentiment:\", predicted_sentiment)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
